{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if eager mode is working\n",
    "tfe.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get version of tf in ypur computer\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    }
   ],
   "source": [
    "#test the eager execution\n",
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(\"hello, {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define circuit and qnode\n",
    "dev2 = qml.device('default.qubit', wires=3)\n",
    "\n",
    "@qml.qnode(dev2, interface='tfe')\n",
    "def circuit2(p1, p2):\n",
    "    qml.Rot(p1[0], p1[1], p1[2], wires=1)\n",
    "    qml.Rot(p2[0], p2[1], p2[2], wires=2)\n",
    "    return qml.expval.PauliZ(0), qml.expval.PauliZ(1), qml.expval.PauliZ(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tfe.Variable(tf.random.normal([3], dtype=tf.float64))\n",
    "t2 = tfe.Variable(tf.random.normal([3], dtype=tf.float64))\n",
    "#t1 = tfe.Variable([0, np.pi, 0], dtype=tf.float64)\n",
    "#t2 = tfe.Variable([0, np.pi, 0], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([-0.24696728,  0.76951318, -0.26863317])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using J=[1,-1] as default couplings\n",
    "def cost(var):\n",
    "#   J= tf.constant([1, -1])\n",
    "    spins = circuit2(var[0], var[1])\n",
    "    energy = -(1*spins[0]*spins[1])-(-1*spins[1]*spins[2])\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: t1 = [-0.246967, 0.756233, -0.268633], t2 = [-1.401288, 0.670313, 0.611821], loss = -0.13708429784352494\n",
      "Step 5: t1 = [-0.246967, 0.663433, -0.268633], t2 = [-1.401288, 0.930258, 0.611821], loss = -0.275460537793314\n",
      "Step 10: t1 = [-0.246967, 0.516825, -0.268633], t2 = [-1.401288, 1.287442, 0.611821], loss = -0.5496015696296994\n",
      "Step 15: t1 = [-0.246967, 0.329050, -0.268633], t2 = [-1.401288, 1.732467, 0.611821], loss = -0.9971901565841157\n",
      "Step 20: t1 = [-0.246967, 0.161894, -0.268633], t2 = [-1.401288, 2.182695, 0.611821], loss = -1.4758278042230473\n",
      "Step 25: t1 = [-0.246967, 0.064369, -0.268633], t2 = [-1.401288, 2.538981, 0.611821], loss = -1.7820146837012802\n",
      "Step 30: t1 = [-0.246967, 0.022786, -0.268633], t2 = [-1.401288, 2.777232, 0.611821], loss = -1.9188822480212904\n",
      "Step 35: t1 = [-0.246967, 0.007681, -0.268633], t2 = [-1.401288, 2.924604, 0.611821], loss = -1.9710478454170068\n",
      "Step 40: t1 = [-0.246967, 0.002543, -0.268633], t2 = [-1.401288, 3.013078, 0.611821], loss = -1.9898199116920308\n",
      "Step 45: t1 = [-0.246967, 0.000836, -0.268633], t2 = [-1.401288, 3.065626, 0.611821], loss = -1.996439703240794\n",
      "Step 50: t1 = [-0.246967, 0.000274, -0.268633], t2 = [-1.401288, 3.096719, 0.611821], loss = -1.9987572603662134\n",
      "Step 55: t1 = [-0.246967, 0.000090, -0.268633], t2 = [-1.401288, 3.115092, 0.611821], loss = -1.9995665165644407\n",
      "Step 60: t1 = [-0.246967, 0.000029, -0.268633], t2 = [-1.401288, 3.125943, 0.611821], loss = -1.999848832969563\n",
      "Step 65: t1 = [-0.246967, 0.000010, -0.268633], t2 = [-1.401288, 3.132352, 0.611821], loss = -1.999947288755618\n",
      "Step 70: t1 = [-0.246967, 0.000003, -0.268633], t2 = [-1.401288, 3.136136, 0.611821], loss = -1.9999816204098257\n",
      "Step 75: t1 = [-0.246967, 0.000001, -0.268633], t2 = [-1.401288, 3.138371, 0.611821], loss = -1.9999935913943512\n",
      "Step 80: t1 = [-0.246967, 0.000000, -0.268633], t2 = [-1.401288, 3.139690, 0.611821], loss = -1.9999977654526306\n",
      "Step 85: t1 = [-0.246967, 0.000000, -0.268633], t2 = [-1.401288, 3.140469, 0.611821], loss = -1.9999992208609327\n",
      "Step 90: t1 = [-0.246967, 0.000000, -0.268633], t2 = [-1.401288, 3.140929, 0.611821], loss = -1.9999997283309363\n",
      "Step 95: t1 = [-0.246967, 0.000000, -0.268633], t2 = [-1.401288, 3.141201, 0.611821], loss = -1.9999999052748463\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost([t1, t2])\n",
    "        grads = tape.gradient(loss, [t1, t2])\n",
    "\n",
    "    opt.apply_gradients(zip(grads, [t1, t2]), global_step=tf.train.get_or_create_global_step())\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(\"Step {}: t1 = [{:f}, {:f}, {:f}], t2 = [{:f}, {:f}, {:f}], loss = {}\".format(i,\n",
    "                *t1.numpy(), *t2.numpy(), loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
